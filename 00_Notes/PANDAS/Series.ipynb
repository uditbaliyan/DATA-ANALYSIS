{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        19\n",
      "1         9\n",
      "2        23\n",
      "3        10\n",
      "4        17\n",
      "         ..\n",
      "41139    19\n",
      "41140    20\n",
      "41141    18\n",
      "41142    18\n",
      "41143    16\n",
      "Name: city08, Length: 41144, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4094/1734387650.py:2: DtypeWarning: Columns (68,70,71,72,73,74,76,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "url = 'vehicles.csv'\n",
    "df = pd.read_csv(url)\n",
    "city_mpg = pd.Series(df.city08)\n",
    "print(f\"{city_mpg}\")\n",
    "highway_mpg = df.highway08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.369045304297103\n",
      "7.9058861707373005\n",
      "17.0\n",
      "755776\n",
      "41144\n"
     ]
    }
   ],
   "source": [
    "print(f\"{city_mpg.mean()}\\n{city_mpg.std()}\\n{city_mpg.median()}\\n{city_mpg.sum()}\\n{city_mpg.count()}\")\n",
    "# city_mpg.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zfill',\n",
       " 'wrap',\n",
       " 'upper',\n",
       " 'translate',\n",
       " 'title',\n",
       " 'swapcase',\n",
       " 'strip',\n",
       " 'startswith',\n",
       " 'split',\n",
       " 'slice_replace',\n",
       " 'slice',\n",
       " 'rstrip',\n",
       " 'rsplit',\n",
       " 'rpartition',\n",
       " 'rjust',\n",
       " 'rindex',\n",
       " 'rfind',\n",
       " 'replace',\n",
       " 'repeat',\n",
       " 'removesuffix',\n",
       " 'removeprefix',\n",
       " 'partition',\n",
       " 'pad',\n",
       " 'normalize',\n",
       " 'match',\n",
       " 'lstrip',\n",
       " 'lower',\n",
       " 'ljust',\n",
       " 'len',\n",
       " 'join',\n",
       " 'isupper',\n",
       " 'istitle',\n",
       " 'isspace',\n",
       " 'isnumeric',\n",
       " 'islower',\n",
       " 'isdigit',\n",
       " 'isdecimal',\n",
       " 'isalpha',\n",
       " 'isalnum',\n",
       " 'index',\n",
       " 'get_dummies',\n",
       " 'get',\n",
       " 'fullmatch',\n",
       " 'findall',\n",
       " 'find',\n",
       " 'extractall',\n",
       " 'extract',\n",
       " 'endswith',\n",
       " 'encode',\n",
       " 'decode',\n",
       " 'count',\n",
       " 'contains',\n",
       " 'center',\n",
       " 'cat',\n",
       " 'casefold',\n",
       " 'capitalize',\n",
       " '_wrap_result',\n",
       " '_validate',\n",
       " '_parent',\n",
       " '_orig',\n",
       " '_name',\n",
       " '_is_string',\n",
       " '_is_categorical',\n",
       " '_inferred_dtype',\n",
       " '_index',\n",
       " '_get_series_list',\n",
       " '_freeze',\n",
       " '_doc_args',\n",
       " '_data',\n",
       " '__weakref__',\n",
       " '__subclasshook__',\n",
       " '__str__',\n",
       " '__sizeof__',\n",
       " '__setattr__',\n",
       " '__repr__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__new__',\n",
       " '__ne__',\n",
       " '__module__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__iter__',\n",
       " '__init_subclass__',\n",
       " '__init__',\n",
       " '__hash__',\n",
       " '__gt__',\n",
       " '__getstate__',\n",
       " '__getitem__',\n",
       " '__getattribute__',\n",
       " '__ge__',\n",
       " '__frozen',\n",
       " '__format__',\n",
       " '__eq__',\n",
       " '__doc__',\n",
       " '__dir__',\n",
       " '__dict__',\n",
       " '__delattr__',\n",
       " '__class__',\n",
       " '__annotations__']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['aA', 'bB', '1'])\n",
    "\n",
    "# Attributes of the .str accessor\n",
    "dir(s.str)[::-1]\n",
    "# print(f\"{s.str.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    AA\n",
      "1    BB\n",
      "2     1\n",
      "dtype: object\n",
      "0    Aa\n",
      "1    Bb\n",
      "2     1\n",
      "dtype: object\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(f'{s.str.upper()}\\n{s.str.title()}\\n{s.str.isnumeric()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "# Example Series with datetime\n",
    "dt_series = pd.Series(pd.date_range(\"2023-01-01\", periods=3))\n",
    "\n",
    "# Attributes of the .dt accessor\n",
    "dt_attributes = dir(dt_series.dt)\n",
    "print(len(dt_attributes))  # Number of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2023\n",
      "1    2023\n",
      "2    2023\n",
      "dtype: int32\n",
      "0     Sunday\n",
      "1     Monday\n",
      "2    Tuesday\n",
      "dtype: object\n",
      "0    2023-01-01\n",
      "1    2023-01-02\n",
      "2    2023-01-03\n",
      "dtype: object\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"{dt_series.dt.year}\\n{dt_series.dt.day_name()}\\n{dt_series.dt.date}\\n{dt_series.dt.day}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     NaN\n",
       "2    55.0\n",
       "2    64.0\n",
       "2    65.0\n",
       "2    74.0\n",
       "4     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd . Series ([10 , 20 , 30] , index =[1 ,2 ,2])\n",
    "s2 = pd . Series ([35 , 44 , 53] , index =[2 ,2 ,4] , name =' s2 ')\n",
    "s1 + s2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s1.add(s2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.0\n",
       "2    55.0\n",
       "2    64.0\n",
       "2    65.0\n",
       "2    74.0\n",
       "4    43.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.add(s2,fill_value=-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, here is the information in a three-column tabular format:\n",
    "\n",
    "| Method | Operator | Description |\n",
    "|---|---|---|\n",
    "| **Addition Operations** | | |\n",
    "| `s.add(s2)` | `s + s2` | Adds series |\n",
    "| `s2 + s` | | Adds series |\n",
    "| **Subtraction Operations** | | |\n",
    "| `s.sub(s2)` | `s - s2` | Subtracts series |\n",
    "| `s2 - s` | | Subtracts series |\n",
    "| **Multiplication Operations** | | |\n",
    "| `s.mul(s2)` / `s.multiply(s2)` | `s * s2` | Multiplies series |\n",
    "| `s2 * s` | | Multiplies series |\n",
    "| **Division Operations** | | |\n",
    "| `s.div(s2)` / `s.truediv(s2)` | `s / s2` | Divides series |\n",
    "| `s2 / s` | | Divides series |\n",
    "| `s.rdiv(s2)` / `s.rtruediv(s2)` | | Divides series (reversed) |\n",
    "| **Modulo Operations** | | |\n",
    "| `s.mod(s2)` | `s % s2` | Modulo of series division |\n",
    "| `s2 % s` | | Modulo of series division (reversed) |\n",
    "| **Floor Division Operations** | | |\n",
    "| `s.floordiv(s2)` | `s // s2` | Floor divides series |\n",
    "| `s2 // s` | | Floor divides series (reversed) |\n",
    "| **Exponential Operations** | | |\n",
    "| `s.pow(s2)` | `s ** s2` | Exponential power of series |\n",
    "| `s2 ** s` | | Exponential power of series (reversed) |\n",
    "| **Comparison Operations** | | |\n",
    "| `s.eq(s2)` | `s2 == s` | Elementwise equals of series |\n",
    "| `s.ne(s2)` | `s2 != s` | Elementwise not equals of series |\n",
    "| `s.gt(s2)` | `s > s2` | Elementwise greater than of series |\n",
    "| `s.ge(s2)` | `s >= s2` | Elementwise greater than or equals of series |\n",
    "| `s.lt(s2)` | `s < s2` | Elementwise less than of series |\n",
    "| `s.le(s2)` | `s <= s2` | Elementwise less than or equals of series |\n",
    "| **Logical Operations** | | |\n",
    "| `np.invert(s)` | `~s` | Elementwise inversion of boolean series (no direct pandas method) |\n",
    "| `np.logical_and(s, s2)` | `s & s2` | Elementwise logical and of boolean series (no direct pandas method) |\n",
    "| `np.logical_or(s, s2)` | `s | s2` | Elementwise logical or of boolean series (no direct pandas method) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.9 Exercises\n",
    "With a dataset of your choice:\n",
    "1. Add a numeric series to itself.\n",
    "2. Add 10 to a numeric series.\n",
    "3. Add a numeric series to itself using the .add method.\n",
    "4. Read the documentation for the .add method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6     2\n",
      "5     4\n",
      "4     6\n",
      "3     8\n",
      "2    10\n",
      "1    12\n",
      "dtype: int64\n",
      "\n",
      "6    11\n",
      "5    12\n",
      "4    13\n",
      "3    14\n",
      "2    15\n",
      "1    16\n",
      "dtype: int64\n",
      "\n",
      "6    11\n",
      "5    12\n",
      "4    13\n",
      "3    14\n",
      "2    15\n",
      "1    16\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Return Addition of series and other, element-wise (binary operator `add`).\n",
      "\n",
      "Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      "missing data in either one of the inputs.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "other : Series or scalar value\n",
      "level : int or name\n",
      "    Broadcast across a level, matching Index values on the\n",
      "    passed MultiIndex level.\n",
      "fill_value : None or float value, default None (NaN)\n",
      "    Fill existing missing (NaN) values, and any new element needed for\n",
      "    successful Series alignment, with this value before computation.\n",
      "    If data in both corresponding Series locations is missing\n",
      "    the result of filling (at that location) will be missing.\n",
      "axis : {0 or 'index'}\n",
      "    Unused. Parameter needed for compatibility with DataFrame.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "Series\n",
      "    The result of the operation.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "Series.radd : Reverse of the Addition operator, see\n",
      "    `Python documentation\n",
      "    <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      "    for more details.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      ">>> a\n",
      "a    1.0\n",
      "b    1.0\n",
      "c    1.0\n",
      "d    NaN\n",
      "dtype: float64\n",
      ">>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      ">>> b\n",
      "a    1.0\n",
      "b    NaN\n",
      "d    1.0\n",
      "e    NaN\n",
      "dtype: float64\n",
      ">>> a.add(b, fill_value=0)\n",
      "a    2.0\n",
      "b    1.0\n",
      "c    1.0\n",
      "d    1.0\n",
      "e    NaN\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s=pd.Series(data=[1,2,3,4,5,6],index=[6,5,4,3,2,1],dtype=int)\n",
    "s+s\n",
    "print(f\"{s.add(s,fill_value=-1)}\\n\\n{s.add(10)}\\n\\n{s+10}\\n\\n{s.add.__doc__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7\n",
    "Aggregate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum = 755776\n",
      "mean = 18.369045304297103\n",
      "median = 17.0\n",
      "min = 6\n",
      "max = 150\n",
      "unique = False\n",
      "monotonic_decreasing = False\n",
      "monotonic_increasing = False\n",
      "quantile (.9) = 24.0\n",
      "quantile ([.1 , .5 , .9] = 0.1    13.0\n",
      "0.5    17.0\n",
      "0.9    24.0\n",
      "Name: city08, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"sum = {city_mpg . sum ()}\")\n",
    "print(f\"mean = {city_mpg . mean ()}\")\n",
    "print(f\"median = {city_mpg . median ()}\")\n",
    "print(f\"min = {city_mpg . min ()}\")\n",
    "print(f\"max = {city_mpg . max ()}\")\n",
    "\n",
    "print(f\"unique = {city_mpg . is_unique}\")\n",
    "\n",
    "print(f\"monotonic_decreasing = {city_mpg . is_monotonic_decreasing}\")\n",
    "print(f\"monotonic_increasing = {city_mpg . is_monotonic_increasing}\")\n",
    "\n",
    "print(f\"quantile (.9) = {city_mpg . quantile (.9)}\\nquantile ([.1 , .5 , .9] = {city_mpg . quantile ([.1 , .5 , .9])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count and Mean of an Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_mpg. gt (20). sum () = 10272\n",
      "10272\n",
      "city_mpg. gt (20). mul (100). mean () = 24.965973167412017\n"
     ]
    }
   ],
   "source": [
    "print(f\"city_mpg. gt (20). sum () = {( city_mpg. gt (20). sum ())}\")\n",
    "print(f'{city_mpg. gt (20).count()}')\n",
    "print(f\"city_mpg. gt (20). mul (100). mean () = { city_mpg. gt (20). mul (100). mean ()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3914/3584400096.py:6: FutureWarning: The provided callable <function var at 0x7f3312dbe340> is currently using Series.var. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"var\" instead.\n",
      "  city_mpg . agg ([  np . var , max , second_to_last ])\n",
      "/tmp/ipykernel_3914/3584400096.py:6: FutureWarning: The provided callable <built-in function max> is currently using Series.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  city_mpg . agg ([  np . var , max , second_to_last ])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "var                62.503036\n",
       "max               150.000000\n",
       "second_to_last     18.000000\n",
       "Name: city08, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def second_to_last (s ):\n",
    "\n",
    "    return s . iloc [ -2]\n",
    "\n",
    "city_mpg . agg ([  np . var , max , second_to_last ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the information presented in a three-column tabular format:\n",
    "\n",
    "| Method | Description |\n",
    "|---|---|\n",
    "| **Boolean Methods** | |\n",
    "| `'all'` | Returns True if every value is truthy. |\n",
    "| `'any'` | Returns True if any value is truthy. |\n",
    "| `'autocorr'` | Returns Pearson correlation of series with shifted self. Can override lag as a keyword argument (default is 1). |\n",
    "| `'corr'` | Returns Pearson correlation of series with another series. Need to specify other. |\n",
    "| `'count'` | Returns count of non-missing values. |\n",
    "| `'cov'` | Returns covariance of series with another series. Need to specify other. |\n",
    "| `'dtype'` | Type of the series. |\n",
    "| `'dtypes'` | Type of the series. |\n",
    "| `'empty'` | True if no values in series. |\n",
    "| `'hasnans'` | True if missing values in series. |\n",
    "| **Aggregate Methods** | |\n",
    "| `'idxmax'` | Returns index value of maximum value. |\n",
    "| `'idxmin'` | Returns index value of minimum value. |\n",
    "| `'is_monotonic'` | True if values always increase. |\n",
    "| `'is_monotonic_decreasing'` | True if values always decrease. |\n",
    "| `'is_monotonic_increasing'` | True if values always increase. |\n",
    "| `'kurt'` | Return ”excess” kurtosis (0 is normal distribution). Values greater than 0 have more outliers than normal. |\n",
    "| `'mad'` | Return the mean absolute deviation. |\n",
    "| `'max'` | Return the maximum value. |\n",
    "| `'mean'` | Return the mean value. |\n",
    "| `'median'` | Return the median value. |\n",
    "| `'min'` | Return the minimum value. |\n",
    "| `'nbytes'` | Return the number of bytes of the data. |\n",
    "| `'ndim'` | Return the number of dimensions (1) of the data. |\n",
    "| `'nunique'` | Return the count of unique values. |\n",
    "| `'quantile'` | Return the median value. Can override q to specify |\n",
    "| `'sem'` | Return the standard error of the mean. |\n",
    "| `'size'` | Return the number of elements in the series. |\n",
    "| `'skew'` | Return the sample skewness (third moment). |\n",
    "| `'std'` | Return the sample standard deviation. |\n",
    "| `'sum'` | Return the sum of the values. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a markdown table that summarizes the pandas Series methods and their descriptions:\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `s.agg(func=None, axis=0, *args, **kwargs)` | Returns a scalar if `func` is a single aggregation function. Returns a Series if a list of aggregations is passed to `func`. |\n",
    "| `s.all(axis=0, bool_only=None, skipna=True, level=None)` | Returns `True` if every value is truthy. Otherwise `False`. |\n",
    "| `s.any(axis=0, bool_only=None, skipna=True, level=None)` | Returns `True` if at least one value is truthy. Otherwise `False`. |\n",
    "| `s.autocorr(lag=1)` | Returns Pearson correlation between `s` and shifted `s`. |\n",
    "| `s.corr(other, method='pearson')` | Returns correlation coefficient for 'pearson', 'spearman', 'kendall', or a callable. |\n",
    "| `s.cov(other, min_periods=None)` | Returns covariance. |\n",
    "| `s.max(axis=None, skipna=None, level=None, numeric_only=None)` | Returns maximum value. |\n",
    "| `s.min(axis=None, skipna=None, level=None, numeric_only=None)` | Returns minimum value. |\n",
    "| `s.mean(axis=None, skipna=None, level=None, numeric_only=None)` | Returns mean value. |\n",
    "| `s.median(axis=None, skipna=None, level=None, numeric_only=None)` | Returns median value. |\n",
    "| `s.prod(axis=None, skipna=None, level=None, numeric_only=None, min_count=0)` | Returns product of `s` values. |\n",
    "| `s.quantile(q=0.5, interpolation='linear')` | Returns the 50% quantile by default. Returns Series if `q` is a list. |\n",
    "| `s.sem(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)` | Returns unbiased standard error of mean. |\n",
    "| `s.std(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)` | Returns sample standard deviation. |\n",
    "| `s.var(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)` | Returns unbiased variance. |\n",
    "| `s.skew(axis=None, skipna=None, level=None, numeric_only=None)` | Returns unbiased skew. |\n",
    "| `s.kurtosis(axis=None, skipna=None, level=None, numeric_only=None)` | Returns unbiased kurtosis. |\n",
    "| `s.nunique(dropna=True)` | Returns the number of unique values. |\n",
    "| `s.count(level=None)` | Returns the number of non-null values. |\n",
    "| `s.size` | Returns the number of elements in the Series. |\n",
    "| `s.is_unique` | Returns `True` if all values are unique. |\n",
    "| `s.is_monotonic` | Returns `True` if the values are monotonically increasing or decreasing. |\n",
    "| `s.is_monotonic_increasing` | Returns `True` if the values are monotonically increasing. |\n",
    "| `s.is_monotonic_decreasing` | Returns `True` if the values are monotonically decreasing. |\n",
    "\n",
    "This table provides a quick reference to various pandas Series methods and their functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4\n",
    "Summary\n",
    "In this chapter, we discussed ways to summarize data in a series. As you begin to analyze data,\n",
    "you will ﬁnd many of these keep popping up. One thing to keep in mind is that they also apply to\n",
    "a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.5\n",
    "Exercises\n",
    "With a dataset of your choice:\n",
    "1. Find the count of non-missing values of a series.\n",
    "2. Find the number of entries of a series.\n",
    "3. Find the number of unique entries of a series.\n",
    "4. Find the mean value of a series.\n",
    "5. Find the maximum value of a series.\n",
    "6. Use the .agg method to ﬁnd all of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8\n",
    "Conversion Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         9\n",
       "2        23\n",
       "3        10\n",
       "4        17\n",
       "         ..\n",
       "41139    19\n",
       "41140    20\n",
       "41141    18\n",
       "41142    18\n",
       "41143    16\n",
       "Name: city08, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg . convert_dtypes ()\n",
    "city_mpg . astype ( 'Int16')\n",
    "city_mpg . astype ( 'str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for int64\n",
      "---------------------------------------------------------------\n",
      "min = -9223372036854775808\n",
      "max = 9223372036854775807\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for uint8\n",
      "---------------------------------------------------------------\n",
      "min = 0\n",
      "max = 255\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for float16\n",
      "---------------------------------------------------------------\n",
      "precision =   3   resolution = 1.00040e-03\n",
      "machep =    -10   eps =        9.76562e-04\n",
      "negep =     -11   epsneg =     4.88281e-04\n",
      "minexp =    -14   tiny =       6.10352e-05\n",
      "maxexp =     16   max =        6.55040e+04\n",
      "nexp =        5   min =        -max\n",
      "smallest_normal = 6.10352e-05   smallest_subnormal = 5.96046e-08\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for float64\n",
      "---------------------------------------------------------------\n",
      "precision =  15   resolution = 1.0000000000000001e-15\n",
      "machep =    -52   eps =        2.2204460492503131e-16\n",
      "negep =     -53   epsneg =     1.1102230246251565e-16\n",
      "minexp =  -1022   tiny =       2.2250738585072014e-308\n",
      "maxexp =   1024   max =        1.7976931348623157e+308\n",
      "nexp =       11   min =        -max\n",
      "smallest_normal = 2.2250738585072014e-308   smallest_subnormal = 4.9406564584124654e-324\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"{np . iinfo ( 'int64')}\")\n",
    "print(f\"{np . iinfo ( 'uint8')}\")\n",
    "print(f\"{np . finfo ( 'float16')}\")\n",
    "print(f\"{np . finfo ( 'float64')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123432"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{ city_mpg . nbytes}\")\n",
    "city_mpg . astype ( 'Int16'). nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2606399"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make = df.make\n",
    "make.nbytes\n",
    "make.memory_usage ()\n",
    "make.memory_usage ( deep = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String and Category Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         9\n",
       "2        23\n",
       "3        10\n",
       "4        17\n",
       "         ..\n",
       "41139    19\n",
       "41140    20\n",
       "41141    18\n",
       "41142    18\n",
       "41143    16\n",
       "Name: city08, Length: 41144, dtype: category\n",
       "Categories (105, int64): [6, 7, 8, 9, ..., 137, 138, 140, 150]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.astype(str)\n",
    "city_mpg.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.4 Ordered Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        6\n",
       "1        7\n",
       "2        8\n",
       "3        9\n",
       "4       10\n",
       "      ... \n",
       "100    136\n",
       "101    137\n",
       "102    138\n",
       "103    140\n",
       "104    150\n",
       "Length: 105, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = pd.Series(sorted(set(city_mpg)))\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String or Type\n",
    "Description\n",
    "str 'str'\n",
    "Convert type to Python string\n",
    "'string'\n",
    "Convert type to pandas string (supports\n",
    "pd.NA)\n",
    "int 'int' 'int64'\n",
    "Convert type to NumPy int64\n",
    "Convert type to 32 signed or unsigned\n",
    "'int32' 'uint32'\n",
    "NumPy integer (can also use 16 and 8).\n",
    "'Int64'\n",
    "Convert type to pandas Int64 (supports\n",
    "pd.NA). Might complain when you\n",
    "convert ﬂoats or strings.\n",
    "float 'float' 'float64'\n",
    "Convert type to NumPy ﬂoat64 (can also\n",
    "support 32 or 16).\n",
    "'category'\n",
    "Convert type to categorical (supports\n",
    "pd.NA). Can also use instance of\n",
    "CategoricalDtype.\n",
    "dates\n",
    "Don’t use this for date conversion, use\n",
    "pd.to_datetime.\n",
    "Table 8.1: Type and strings for column conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.5 Converting to Other Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a table with descriptions for the mentioned methods, formatted for clarity:\n",
    "\n",
    "| **Method**                                                                                         | **Description**                                                                                         |\n",
    "|----------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| `s.convert_dtypes(infer_objects=True, convert_string=True, convert_integer=True, convert_boolean=True, convert_floating=True)` | Convert types to appropriate pandas types (that support NA). Doesn’t try to reduce size of integer or float types. |\n",
    "| `s.astype(dtype, copy=True, errors='raise')`                                                       | Cast series into a particular type. If `errors='ignore'`, then return the original series on error.     |\n",
    "| `pd.to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False, utc=None, format=None, exact=True, unit=None, infer_datetime_format=False, origin='unix', cache=True)` | Convert arg (a series) into datetime. Use format to specify strftime string.                             |\n",
    "| `s.to_numpy(dtype=None, copy=False, na_value=object, **kwargs)`                                     | Convert the series to a NumPy array.                                                                     |\n",
    "| `s.values`                                                                                         | Convert the series to a NumPy array.                                                                     |\n",
    "| `s.to_frame(name=None)`                                                                            | Return a DataFrame representation of the series.                                                         |\n",
    "| `pd.CategoricalDtype(categories=None, ordered=False)`                                              | Create a type for categorical data.                                                                      |\n",
    "\n",
    "This table describes various pandas methods for data type conversion, casting, and transformation of Series objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.6\n",
    "Summary\n",
    "Having the correct types is very convenient. Not only does it save memory, but it also enables\n",
    "operations that are otherwise tedious. Whenever I teach students the fundamentals of data\n",
    "analysis, I make sure that they go through each column and determine what the correct type for\n",
    "that column is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.7 Exercises\n",
    "With a dataset of your choice:\n",
    "1. Convert a numeric column to a smaller type.\n",
    "2. Calculate the memory savings by converting to smaller numeric types.\n",
    "3. Convert a string column into a categorical type.\n",
    "4. Calculate the memory savings by converting to a categorical type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 9\n",
    "Manipulation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 .apply and .where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41144,)\n",
      "make\n",
      "Chevrolet                      4003\n",
      "Ford                           3371\n",
      "Dodge                          2583\n",
      "GMC                            2494\n",
      "Toyota                         2071\n",
      "                               ... \n",
      "Volga Associated Automobile       1\n",
      "Panos                             1\n",
      "Mahindra                          1\n",
      "Excalibur Autos                   1\n",
      "London Coach Co Inc               1\n",
      "Name: count, Length: 136, dtype: int64\n",
      "make\n",
      "Chevrolet    4003\n",
      "Ford         3371\n",
      "Dodge        2583\n",
      "GMC          2494\n",
      "Toyota       2071\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"{make.shape}\")\n",
    "print(f\"{ make.value_counts ()}\")\n",
    "print(f\"{make . value_counts ()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Other \n",
       "1         Other \n",
       "2          Dodge\n",
       "3          Dodge\n",
       "4         Other \n",
       "          ...   \n",
       "41139     Other \n",
       "41140     Other \n",
       "41141     Other \n",
       "41142     Other \n",
       "41143     Other \n",
       "Name: make, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5 = make . value_counts (). index [:5]\n",
    "def generalize_top5 ( val ):\n",
    "\n",
    "    if val in top5 :\n",
    "        return val\n",
    "\n",
    "    return ' Other '\n",
    "\n",
    "make . apply ( generalize_top5 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Other \n",
       "1         Other \n",
       "2          Dodge\n",
       "3          Dodge\n",
       "4         Other \n",
       "          ...   \n",
       "41139     Other \n",
       "41140     Other \n",
       "41141     Other \n",
       "41142     Other \n",
       "41143     Other \n",
       "Name: make, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make . where ( make . isin ( top5 ), other =' Other ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 If Else with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Other\n",
       "1        Other\n",
       "2        Dodge\n",
       "3        Dodge\n",
       "4        Other\n",
       "         ...  \n",
       "41139    Other\n",
       "41140    Other\n",
       "41141    Other\n",
       "41142    Other\n",
       "41143    Other\n",
       "Name: make, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vc = make . value_counts ()\n",
    "top5 = vc . index [:5]\n",
    "top10 = vc . index [:10]\n",
    "def generalize ( val ):\n",
    "    if val in top5 :\n",
    "        return val\n",
    "    elif val in top10 :\n",
    "        return ' Top10 '\n",
    "    else :\n",
    "        return ' Other '\n",
    "make . apply ( generalize )\n",
    "\n",
    "\n",
    "make.where(make.isin(top5),'Top10').where(make.isin(top10),'Other')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.3\n",
    "Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         4.0\n",
      "1        12.0\n",
      "2         4.0\n",
      "3         8.0\n",
      "4         4.0\n",
      "         ... \n",
      "41139     4.0\n",
      "41140     4.0\n",
      "41141     4.0\n",
      "41142     4.0\n",
      "41143     4.0\n",
      "Name: cylinders, Length: 41144, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28557     True\n",
       "8144      True\n",
       "31252     True\n",
       "31396     True\n",
       "31395     True\n",
       "         ...  \n",
       "27352    False\n",
       "27351    False\n",
       "27350    False\n",
       "27349    False\n",
       "0        False\n",
       "Name: cylinders, Length: 41144, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyl = df . cylinders\n",
    "print(f\"{cyl}\")\n",
    "( cyl.isna().sort_values())[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylinders\n",
      "False    40938\n",
      "True       206\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7138     Nissan\n",
       "7139     Toyota\n",
       "8143     Toyota\n",
       "8144       Ford\n",
       "8146       Ford\n",
       "          ...  \n",
       "34563     Tesla\n",
       "34564     Tesla\n",
       "34565     Tesla\n",
       "34566     Tesla\n",
       "34567     Tesla\n",
       "Name: make, Length: 206, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = cyl . isna ().value_counts()\n",
    "print(f\"{missing}\")\n",
    "missing = cyl . isna ()\n",
    "make . loc [ missing ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "We often use the same term to represent different items. In pandas, both a series and a data\n",
    "frame have an index, the value that names each row. In addition, we use an index operation,\n",
    "performed with square brackets ([ and ]), to select values from a series or a data frame.\n",
    "I will try to use the noun ”index” to discuss the member of the series or data frame. If I use\n",
    "”index” as a verb, or say ”index operation”, it is referring to selecting out subsets of data. Below,\n",
    "I am indexing off of the .loc attribute. I could also say that I’m doing an indexing operation:\n",
    "make . loc [ missing ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Filling In Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7138    NaN\n",
       "7139    NaN\n",
       "8143    NaN\n",
       "8144    NaN\n",
       "8146    NaN\n",
       "         ..\n",
       "34563   NaN\n",
       "34564   NaN\n",
       "34565   NaN\n",
       "34566   NaN\n",
       "34567   NaN\n",
       "Name: cylinders, Length: 206, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyl [ cyl . isna ()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyl . fillna (0). loc [7136:7141]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Almost every operation that I show in this book does not mutate data. In other words, the\n",
    "above operation returns a new series with the missing values replaced by zero. If I want to\n",
    "update my cyl variable, I would need to assign it to this new result. Usually, I end up chaining\n",
    "each command and build up a sequence of operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Interpolating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    41.0\n",
       "1    32.0\n",
       "2    40.0\n",
       "3    41.0\n",
       "4    42.0\n",
       "5    39.0\n",
       "6    32.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd . Series ([41,32 , 40 , None , 42 , 39 , 32])\n",
    "temp . interpolate ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6 Clipping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      19\n",
       "1       9\n",
       "2      23\n",
       "3      10\n",
       "4      17\n",
       "       ..\n",
       "442    15\n",
       "443    15\n",
       "444    15\n",
       "445    15\n",
       "446    31\n",
       "Name: city08, Length: 447, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg . loc [:446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      19\n",
       "1      11\n",
       "2      23\n",
       "3      11\n",
       "4      17\n",
       "       ..\n",
       "442    15\n",
       "443    15\n",
       "444    15\n",
       "445    15\n",
       "446    27\n",
       "Name: city08, Length: 447, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg. loc [:446]. clip ( lower = city_mpg . quantile (.05) ,upper = city_mpg . quantile (.95))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.7\n",
    "Sorting Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        44\n",
       "1        23\n",
       "2        56\n",
       "3        22\n",
       "4        40\n",
       "         ..\n",
       "41139    45\n",
       "41140    48\n",
       "41141    42\n",
       "41142    42\n",
       "41143    37\n",
       "Length: 41144, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( city_mpg . sort_values () + highway_mpg ) /2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.8 Sorting the Index\n",
    "If you want to sort the index of a series, you can use the .sort_index method. Below we unsort the\n",
    "index by sorting the values, then essentially revert that:\n",
    "```city_mpg . sort_values (). sort_index ()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.9 Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         19\n",
       "1          9\n",
       "2         23\n",
       "3         10\n",
       "4         17\n",
       "        ... \n",
       "34364    127\n",
       "34409    114\n",
       "34564    140\n",
       "34565    115\n",
       "34566    104\n",
       "Name: city08, Length: 105, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg . drop_duplicates ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.10 Ranking Data\n",
    "The .rank method will return a series that keeps the original index but uses the ranks of values from\n",
    "the original series. You can control how ranking occurs with the method parameter. By default, if\n",
    "two values are the same, their rank will be the average of the positions they take. Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        27060.5\n",
       "1          235.5\n",
       "2        35830.0\n",
       "3          607.5\n",
       "4        19484.0\n",
       "          ...   \n",
       "41139    27060.5\n",
       "41140    29719.5\n",
       "41141    23528.0\n",
       "41142    23528.0\n",
       "41143    15479.0\n",
       "Name: city08, Length: 41144, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg . rank ()\n",
    "city_mpg . rank ( method = ' min ')\n",
    "city_mpg . rank ( method = ' dense ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.11 Replacing Data\n",
    "The .replace method allows you to map values to new values. There are many ways to specify\n",
    "how to replace the values. You can specify a whole string to replace a string or use a dictionary to\n",
    "map old values to new values. This example uses the former:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make . replace (' Subaru ', ' スバル ')\n",
    "make . replace (r '( Fer ) ra (r .*) ' ,value =r '\\2 - other -\\1 ' , regex = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.12 Binning Data\n",
    "You can bin data as well. Using the cut function, you can create bins of equal width:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd . cut ( city_mpg , 10)\n",
    "pd . cut ( city_mpg , [0 , 10 , 20 , 40 , 70 , 150])\n",
    "pd . qcut ( city_mpg , 10)\n",
    "pd . qcut ( city_mpg , 10 , labels = list ( range (1 ,11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table summarizing various pandas Series methods, their parameters, and their descriptions:\n",
    "\n",
    "| Method | Parameters | Description |\n",
    "| --- | --- | --- |\n",
    "| `s.apply` | `func, convert_dtype=True, args=(), **kwds` | Pass a NumPy function that works on the series, or a Python function that works on a single value. `args` and `kwds` are arguments for `func`. Returns a series or DataFrame if `func` returns a series. |\n",
    "| `s.where` | `cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False` | Pass a boolean series/DataFrame, list, or callable as `cond`. If the value is `True`, keep it; otherwise, use `other` value. If it is a function, it takes a series and should return a boolean sequence. |\n",
    "| `np.select` | `condlist, choicelist, default=0` | Pass a list of boolean arrays for `condlist`. If the value is true, use the corresponding value from `choicelist`. If multiple conditions are `True`, only use the first. Returns a NumPy array. |\n",
    "| `s.fillna` | `value=None, method=None, axis=None, inplace=False, limit=None, downcast=None` | Pass a scalar, dict, series, or DataFrame for `value`. If it is a scalar, use that value; otherwise, use the index from the old value to the new value. |\n",
    "| `s.interpolate` | `method='linear', axis=0, limit=None, inplace=False, limit_direction=None, limit_area=None, downcast=None, **kwargs` | Perform interpolation with missing values. `method` may be 'linear', 'time', among others. |\n",
    "| `s.clip` | `lower=None, upper=None, axis=None, inplace=False, *args, **kwargs` | Return a new series with values clipped to `lower` and `upper`. |\n",
    "| `s.sort_values` | `axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None` | Return a series with values sorted. The `kind` option may be 'quicksort', 'mergesort' (stable), or 'heapsort'. `na_position` indicates the location of NaNs and may be 'first' or 'last'. |\n",
    "| `s.sort_index` | `axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index=False, key=None` | Return a series with the index sorted. The `kind` option may be 'quicksort', 'mergesort' (stable), or 'heapsort'. `na_position` indicates the location of NaNs and may be 'first' or 'last'. |\n",
    "| `s.drop_duplicates` | `keep='first', inplace=False` | Drop duplicates. `keep` may be 'first', 'last', or `False`. (If `False`, it removes all values that were duplicated). |\n",
    "| `s.rank` | `axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False` | Return a series with numerical ranks. `method` allows you to specify tie handling: 'average', 'min', 'max', 'first' (uses the order they appear in series), 'dense' (like 'min', but rank only increases by one after tie). `na_option` allows you to specify NaN handling: 'keep' (stay at NaN), 'top' (move to smallest), 'bottom' (move to largest). |\n",
    "| `s.replace` | `to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad'` | Return a series with new values. `to_replace` can be many things. If it is a string, number, or regular expression, you can replace it with a scalar value. It can also be a list of those things, which requires `values` to be a list of the same size. Finally, it can be a dictionary mapping old values to new values. |\n",
    "| `pd.cut` | `x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False, duplicates='raise', ordered=True` | Bin values from `x` (a series). If `bins` is an integer, use equal-width bins. If `bins` is a list of numbers (defining minimum and maximum positions), use those for the edges. `right` defines whether the right edge is open or closed. `labels` allows you to specify the bin names. Out-of-bounds values will be missing. |\n",
    "| `pd.qcut` | `x, q, labels=None, retbins=False, precision=3, duplicates='raise'` | Bin values from `x` (a series) into `q` equal-sized bins (10 for deciles, 4 for quartiles). Alternatively, you can pass in a list of quantile edges. Out-of-bounds values will be missing. |\n",
    "\n",
    "This table summarizes the parameters and descriptions for these pandas and NumPy methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.13 Summary\n",
    "In this chapter, we explored many methods and functions that are useful for changing the data. We\n",
    "saw how to use function application with the .apply method, but try to avoid that and use np.select\n",
    "instead to get better performance. We discussed various ways to deal with missing data. We saw\n",
    "that we can sort both the values and the index. We can replace data and we can bin data. These\n",
    "operations will come in useful as you begin to analyze data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.14 Exercises\n",
    "With a dataset of your choice:\n",
    "1. Create a series from a numeric column that has the value of 'high' if it is equal to or above\n",
    "the mean and 'low' if it is below the mean using .apply.\n",
    "2. Create a series from a numeric column that has the value of 'high' if it is equal to or above\n",
    "the mean and 'low' if it is below the mean using np.select.\n",
    "3. Time the differences between the previous two solutions to see which is faster.\n",
    "4. Replace the missing values of a numeric series with the median value.\n",
    "5. Clip the values of a numeric series to between to 10th and 90th percentiles.\n",
    "619. Manipulation Methods\n",
    "6. Using a categorical column, replace any value that is not in the top 5 most frequent values\n",
    "with 'Other'.\n",
    "7. Using a categorical column, replace any value that is not in the top 10 most frequent values\n",
    "with 'Other'.\n",
    "8. Make a function that takes a categorical series and a number (n) and returns a replace series\n",
    "that replaces any value that is not in the top n most frequent values with 'Other'.\n",
    "9. Using a numeric column, bin it into 10 groups that have the same width.\n",
    "10. Using a numeric column, bin it into 10 groups that have equal sized bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10\n",
    "Indexing Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alfa Romeo    19\n",
       "Ferrari        9\n",
       "Dodge         23\n",
       "Dodge         10\n",
       "Subaru        17\n",
       "              ..\n",
       "Subaru        19\n",
       "Subaru        20\n",
       "Subaru        18\n",
       "Subaru        18\n",
       "Subaru        16\n",
       "Name: city08, Length: 41144, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg . rename ( make . to_dict ())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
